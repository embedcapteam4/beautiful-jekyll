---
layout: post
title: Week 7
subtitle: Integrating the Training System and Web App, Debugging Gesture Development
tags: [weekly]
---

## Updates:
---

### Facial Recognition: (Ryan, Kurtis, Brad)
This last week we mostly focused on implementing the training procedure for facial recognition. In order for a face to be recognized, the sets of pictures must be compiled into a training file. The training file is built using OpenCV. Then this file can be used in real time to compare the person standing in front of the camera to the training set in order to find a match.

Previously, setting up the training file required using the command line to run Python scripts that called OpenCV functions. To make the training process more user friendly, we set up an automated process. Now to train a new user, the person simply stands in front of the mirror and a web address is displayed. The new user goes to the webpage and registers their account. Once registered, the training process begins and starts capturing images. Once enough images are captured, the training finished up and restarts the mirror. Now when that user stands in front of the mirror they will be recognized and greeted with a welcome message!

Here is a few screenshots of the training process in action. First we see the link displayed where you enter your new user name. Then we see the image capture in progress.
<figure>
	<img style="width: 50%; height: 50%" src="{{ '/img/mirror_setup_capture.jpg' | prepend: site.baseurl }}" alt=""> 
	<!-- <figcaption>User In Front of Mirror</figcaption> -->
</figure>
<!-- <figure> -->
<!-- 	<img style="width: 50%; height: 50%" src="{{ '/img/mirror_capture.png' | prepend: site.baseurl }}" alt="">  -->
<!-- 	<\!-- <figcaption>Mirror Recognizing User</figcaption> -\-> -->
<!-- </figure> -->

### Mobile Application: Updates (Brandon)
The login page on the mobile application now is integrated with the facial recognition training procedure. Once a new user registers on the web app, two things happen. A notification is sent to the facial training protocol so that it knows to start the process, and also the new user name is written to a file. Once the training procedure starts it can read that name from the file so it knows what to call the new profile. 

### Gesture Control (Ryan, Kurtis, Brad)
We have received the Hover sensor and have attempted to integrate it into our system. Unfortunately, after hours of debugging and testing, we have been unable to get any gesture signals back from the sensors. Problems that we have already hypothesized and attempted to fix include incorrectly configured I2C drivers, lack of support for 'repeated starts' in the RaspPi3's I2C drivers, and faulty wires/wiring. Thus, we have concluded that it is the sensor itself that is broken. We have composed and sent an e-mail to the creators of the Hover sensor, and we are hoping that they will be able to assist us.

### Smart Mirror ON/OFF Protocol (Brad)
No Updates

### Smart Mirror Frame (Ryan, Kurtis, Brandon, Brad)
We were able to measure out the dimensions needed for the acrylic frame on Thursday. The next day, we picked it up from TAP Plastics and is at our workstation. Our hope is that the film, when placed on the acrylic frame, will allow us clear visibility of the monitor placed underneath. We will need to apply the film using some kind of light-soap solution.

<br>
## Next Steps:
---

### Facial Recognition: (Ryan, Kurtis, Brad)
We have a few more improvements that we would like to integrate into the facial recognition feature. One is to improve the facial recognition itself, since we are still having issues with false positives. However, now that the training protocol has been implemented we can really focus on this area. 
Another task is to integrate a button into the training process for a better user experience. This way a user can confirm the training procedure or possibly cancel it if they want to abort the current process. 
Finally, we would like to speed up the training process. Currently it takes about a second or two to capture and process one image during the training procedure. We would like to find a way to optimize the code to speed this up. 

### Mobile Application: (Brandon)
Now that the basic face recognition training is set up, we can look into profile customization using the web app. We would like the user to be able to do log in and customize their mirror layout through the web app. 

### Gesture Control: (Ryan, Kurtis, Brad)
We suspect that our Hover sensor is broken and unfortunately, we will probably not have enough time to wait for another one. Thus, because we really only need just one type of user input (to start training), we are planning to just implement a simple button attached to a GPIO. We have already implemented a button module that we are currently using to interface our Web App and Mirror. We are planning to use this same module for this purpose as well.

### Smart Mirror ON/OFF Protocol (Brad)
Our group still needs to tweak the protocol so that the mirror turns on and off for appropriate distances and time. Also, we will need to implement a way for the proximity sensor module to run while the mirror is in the idle state. We plan to use CEC protocol to toggle the monitor ON/OFF through HDMI.

### Smart Mirror Frame (Ryan, Kurtis, Brandon, Brad)
We still need to order the wood for the frame of the mirror and assemble everything together so it does not look like a prototype. This week we will start taking dimensions and planning the layout for the wooden frame.
